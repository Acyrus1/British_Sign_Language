{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "421d9353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.4.1 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\obinn\\appdata\\roaming\\python\\python38\\site-packages (4.5.5.64)\n",
      "Requirement already satisfied: mediapipe in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (0.8.9.1)\n",
      "Requirement already satisfied: sklearn in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from tensorflow==2.4.1) (1.12)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from tensorflow==2.4.1) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from tensorflow==2.4.1) (2.4.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from tensorflow==2.4.1) (0.15.0)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from tensorflow==2.4.1) (1.15.0)\n",
      "Requirement already satisfied: h5py~=2.10.0 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from tensorflow==2.4.1) (2.10.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from tensorflow==2.4.1) (1.19.5)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from tensorflow==2.4.1) (1.1.2)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from tensorflow==2.4.1) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from tensorflow==2.4.1) (3.7.4.3)\n",
      "Requirement already satisfied: tensorboard~=2.4 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from tensorflow==2.4.1) (2.8.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from tensorflow==2.4.1) (1.6.3)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from tensorflow==2.4.1) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from tensorflow==2.4.1) (3.19.4)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from tensorflow==2.4.1) (1.32.0)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from tensorflow==2.4.1) (0.3.3)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from tensorflow==2.4.1) (1.12.1)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from tensorflow==2.4.1) (0.37.1)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from mediapipe) (4.5.5.64)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from mediapipe) (21.4.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from sklearn) (1.0.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from matplotlib) (4.30.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from matplotlib) (3.0.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from matplotlib) (9.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.27.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (3.3.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (58.0.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.0.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.6.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (5.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (4.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2021.10.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (3.2.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from scikit-learn->sklearn) (1.8.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\obinn\\anaconda3\\envs\\virtualenv\\lib\\site-packages (from scikit-learn->sklearn) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.4.1 --user opencv-python mediapipe sklearn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12754c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv #import openCV\n",
    "import numpy as np\n",
    "import copy # import copy libary\n",
    "import mediapipe as mp #import mediapipe\n",
    "import csv # import CSV libary\n",
    "import itertools \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1053874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoint(selection,status):\n",
    "    num = -1\n",
    "    start = 48 \n",
    "    end = 72 \n",
    "    e = 101 \n",
    "    z = 122\n",
    "    if start <= selection <= end:  # 0 - 25\n",
    "        num = selection - start\n",
    "    if selection == e:  # e\n",
    "        status = 0\n",
    "    if selection == z:  # z\n",
    "        status = 1\n",
    "    return num, status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a0a51fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_bounding_rectangle(img, landMarks):\n",
    "    #get dimensions of image obtain from camera OpenCV\n",
    "    imgWidth,imgHeight = img.shape[1],img.shape[0]\n",
    "\n",
    "    EmptyArray = np.empty((0, 2), int)\n",
    "    \n",
    "\n",
    "    for _, landMark in enumerate(landMarks.landmark):\n",
    "        \n",
    "        landMarkX = min(int(landMark.x * imgWidth), imgWidth - 1)\n",
    "        landMarkY = min(int(landMark.y * imgHeight), imgHeight - 1)\n",
    "\n",
    "        landmarkCoordinates = [np.array((landMarkX, landMarkY))]\n",
    "\n",
    "        EmptyArray = np.append(EmptyArray, landmarkCoordinates, axis=0)\n",
    "\n",
    "    x, y, w, h = cv.boundingRect(EmptyArray)\n",
    "\n",
    "    return [x, y, x + w, y + h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f55f8c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def covert_landmarks_list(img, landMarks):\n",
    "    #get dimensions of image obtain from camera openCV\n",
    "    imgWidth,imgHeight = img.shape[1],img.shape[0]\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    #Height represents the number of pixel rows in the image or the number of pixels in each column of the image array.\n",
    "    #Width represents the number of pixel columns in the image or the number of pixels in each row of the image array.\n",
    "\n",
    "    landMarkList = []\n",
    "    \n",
    "\n",
    "    # iterate over landmarks  x and y to calculate pixel\n",
    "    for _, landMark in enumerate(landMarks.landmark):\n",
    "        landMarkX = min(int(landMark.x * imgWidth), imgWidth - 1)\n",
    "        landMarkY = min(int(landMark.y * imgHeight), imgHeight - 1)\n",
    "        \n",
    "\n",
    "        landMarkList.append([landMarkX, landMarkY])\n",
    "\n",
    "    return landMarkList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bee50f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def landmarks_pre_processing(landMarksList):\n",
    "    # deepcopy landmark\n",
    "    copyLandMarksList = copy.deepcopy(landMarksList)\n",
    "   \n",
    "\n",
    "    # Convert landmarks to relative coordinates\n",
    "    X, Y = 0, 0\n",
    "    for index, landMarksCor in enumerate(copyLandMarksList):\n",
    "        if index == 0:\n",
    "            X,Y = landMarksCor[0], landMarksCor[1]\n",
    "\n",
    "        copyLandMarksList[index][0] = copyLandMarksList[index][0] - X\n",
    "        copyLandMarksList[index][1] = copyLandMarksList[index][1] - Y\n",
    "    \n",
    "\n",
    "    # Convert landmark to one-dimensional list\n",
    "    copyLandMarksList = list(itertools.chain.from_iterable(copyLandMarksList))\n",
    "    \n",
    "\n",
    "    # landmarks is normalized\n",
    "    maxValue = max(list(map(abs, copyLandMarksList)))\n",
    "    \n",
    "    # divide max value by itself\n",
    "\n",
    "    def normalize(x):\n",
    "        return x / maxValue\n",
    "\n",
    "    copyLandMarksList = list(map(normalize, copyLandMarksList))\n",
    "    \n",
    "   \n",
    "\n",
    "    return copyLandMarksList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07911242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saving_landmarks_csv(num, status, landMarksList,):\n",
    "    if status == 0:\n",
    "        pass\n",
    "    if status == 1 and (0 <= num <= 24):\n",
    "        csvPath = 'LandmarksSequence/landmarks.csv'\n",
    "        with open(csvPath, 'a', newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([num, *landMarksList])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb136460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(img, landMarksList):\n",
    "    if len(landMarksList) > 0:\n",
    "        # Thum finger\n",
    "        cv.line(img, tuple(landMarksList[2]), tuple(landMarksList[3]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(img, tuple(landMarksList[2]), tuple(landMarksList[3]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(img, tuple(landMarksList[3]), tuple(landMarksList[4]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(img, tuple(landMarksList[3]), tuple(landMarksList[4]),\n",
    "                (255, 255, 255), 2)\n",
    "\n",
    "        # Index finger\n",
    "        cv.line(img, tuple(landMarksList[5]), tuple(landMarksList[6]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(img, tuple(landMarksList[5]), tuple(landMarksList[6]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(img, tuple(landMarksList[6]), tuple(landMarksList[7]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(img, tuple(landMarksList[6]), tuple(landMarksList[7]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(img, tuple(landMarksList[7]), tuple(landMarksList[8]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(img, tuple(landMarksList[7]), tuple(landMarksList[8]),\n",
    "                (255, 255, 255), 2)\n",
    "\n",
    "        # Middle finger\n",
    "        cv.line(img, tuple(landMarksList[9]), tuple(landMarksList[10]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(img, tuple(landMarksList[9]), tuple(landMarksList[10]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(img, tuple(landMarksList[10]), tuple(landMarksList[11]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(img, tuple(landMarksList[10]), tuple(landMarksList[11]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(img, tuple(landMarksList[11]), tuple(landMarksList[12]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(img, tuple(landMarksList[11]), tuple(landMarksList[12]),\n",
    "                (255, 255, 255), 2)\n",
    "\n",
    "        # Ring finger\n",
    "        cv.line(img, tuple(landMarksList[13]), tuple(landMarksList[14]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(img, tuple(landMarksList[13]), tuple(landMarksList[14]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(img, tuple(landMarksList[14]), tuple(landMarksList[15]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(img, tuple(landMarksList[14]), tuple(landMarksList[15]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(img, tuple(landMarksList[15]), tuple(landMarksList[16]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(img, tuple(landMarksList[15]), tuple(landMarksList[16]),\n",
    "                (255, 255, 255), 2)\n",
    "\n",
    "        # Little finger\n",
    "        cv.line(img, tuple(landMarksList[17]), tuple(landMarksList[18]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(img, tuple(landMarksList[17]), tuple(landMarksList[18]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(img, tuple(landMarksList[18]), tuple(landMarksList[19]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(img, tuple(landMarksList[18]), tuple(landMarksList[19]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(img, tuple(landMarksList[19]), tuple(landMarksList[20]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(img, tuple(landMarksList[19]), tuple(landMarksList[20]),\n",
    "                (255, 255, 255), 2)\n",
    "\n",
    "        # Palm\n",
    "        cv.line(img, tuple(landMarksList[0]), tuple(landMarksList[1]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(img, tuple(landMarksList[0]), tuple(landMarksList[1]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(img, tuple(landMarksList[1]), tuple(landMarksList[2]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(img, tuple(landMarksList[1]), tuple(landMarksList[2]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(img, tuple(landMarksList[2]), tuple(landMarksList[5]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(img, tuple(landMarksList[2]), tuple(landMarksList[5]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(img, tuple(landMarksList[5]), tuple(landMarksList[9]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(img, tuple(landMarksList[5]), tuple(landMarksList[9]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(img, tuple(landMarksList[9]), tuple(landMarksList[13]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(img, tuple(landMarksList[9]), tuple(landMarksList[13]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(img, tuple(landMarksList[13]), tuple(landMarksList[17]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(img, tuple(landMarksList[13]), tuple(landMarksList[17]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(img, tuple(landMarksList[17]), tuple(landMarksList[0]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(img, tuple(landMarksList[17]), tuple(landMarksList[0]),\n",
    "                (255, 255, 255), 2)\n",
    "   \n",
    "    return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78152166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawing_bounding_rectangle(uBrec, img, bRec):\n",
    "    if uBrec:\n",
    "        # Draw rectangle\n",
    "        cv.rectangle(img, (bRec[0], bRec[1]), (bRec[2], bRec[3]),(0, 0, 0), 1)\n",
    "\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06cd4817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_signs(img, bRec, multiHandedness, signLang):\n",
    "    #opevCV\n",
    "    cv.rectangle(img, (bRec[0], bRec[1]), (bRec[2], bRec[1] - 22),(0, 0, 0), -1)\n",
    "    \n",
    "\n",
    "    infoText = multiHandedness.classification[0].label[0:]\n",
    "    if signLang != \"\":\n",
    "        infoText = infoText + ':' + signLang\n",
    "    cv.putText(img, infoText, (bRec[0] + 5, bRec[1] - 4),\n",
    "               cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1, cv.LINE_AA)\n",
    "\n",
    "   \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fecf0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_extraction_info(img, status, num):\n",
    "   \n",
    "    statusInfo = ['saving to CSV']\n",
    "    if 1 <= status <= 2:\n",
    "        cv.putText(img, \"Status:\" + statusInfo[status - 1], (10, 90),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1,\n",
    "                   cv.LINE_AA)\n",
    "        if 0 <= num <= 27:\n",
    "            cv.putText(img, \"NUM:\" + str(num), (10, 110),\n",
    "                       cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1,\n",
    "                       cv.LINE_AA)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65f5e2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class landMarkClassifier(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        modelPath='landmarksSequence/landmarkClassifier.tflite',\n",
    "        numThreads=1,\n",
    "    ):\n",
    "        self.interpreter = tf.lite.Interpreter(model_path=modelPath,\n",
    "                                               num_threads=numThreads)\n",
    "\n",
    "        self.interpreter.allocate_tensors()\n",
    "        self.input_details = self.interpreter.get_input_details()\n",
    "        self.output_details = self.interpreter.get_output_details()\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        landMarksList,\n",
    "    ):\n",
    "        input_details_tensor_index = self.input_details[0]['index']\n",
    "        self.interpreter.set_tensor(\n",
    "            input_details_tensor_index,\n",
    "            np.array([landMarksList], dtype=np.float32))\n",
    "        self.interpreter.invoke()\n",
    "\n",
    "        output_details_tensor_index = self.output_details[0]['index']\n",
    "\n",
    "        result = self.interpreter.get_tensor(output_details_tensor_index)\n",
    "\n",
    "        result_index = np.argmax(np.squeeze(result))\n",
    "\n",
    "        return result_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48641764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    \n",
    "\n",
    "    uBrec = True\n",
    "    \n",
    "\n",
    "    \n",
    "    # setting up Mediapipe  \n",
    "    mpHands = mp.solutions.hands\n",
    "    hands = mpHands.Hands(static_image_mode= True,max_num_hands=2,min_detection_confidence= 0.5, min_tracking_confidence= 0.5,)\n",
    "    \n",
    "\n",
    "    LandMarkClassifier = landMarkClassifier()\n",
    "\n",
    "        # Import labels\n",
    "    with open(r\"C:\\Users\\obinn\\Desktop\\PROJECT DEMO\\landmarksSequence\\landmarksLabel.csv\",encoding='utf-8-sig') as f:\n",
    "        # C:\\Users\\obinn\\Desktop\\PROJECT DEMO\\landmarksSequence\n",
    "        # iterate over the rows\n",
    "        \n",
    "        landMarksLabels = csv.reader(f)\n",
    "        landMarksLabels = [row[0] for row in landMarksLabels]\n",
    "    \n",
    "        \n",
    "\n",
    "    status = 0\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        # Process selection\n",
    "        selection = cv.waitKey(10)\n",
    "        if selection == 27:  # ESC\n",
    "            break\n",
    "        num, status = extract_keypoint(selection, status)\n",
    "\n",
    "        # Setup camera\n",
    "        \n",
    "        success, img = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "        img = cv.flip(img, 1)  #image is Mirrored\n",
    "        \n",
    "        #BGR image is ccopied\n",
    "        BGRImag = copy.deepcopy(img)\n",
    "\n",
    "        #  BGR image is  coverted to RGB for implementation of MediaPipe Detection\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "\n",
    "        img.flags.writeable = False\n",
    "        results = hands.process(img)\n",
    "        img.flags.writeable = True\n",
    "\n",
    "        # multiple hands landmark detection implementation\n",
    "        if results.multi_hand_landmarks is not None:\n",
    "            for multiHandLandMarks, multiHandedness in zip(results.multi_hand_landmarks,results.multi_handedness):\n",
    "                \n",
    "                # appling bounding rectangle\n",
    "                boundingRec = apply_bounding_rectangle(BGRImag,multiHandLandMarks)\n",
    "                \n",
    "                # covert Landmark to list\n",
    "                landMarksList = covert_landmarks_list(BGRImag, multiHandLandMarks)\n",
    "                \n",
    "                    \n",
    "                \n",
    "                # landmarks are processed and mormalised\n",
    "                landmarksPreProcessed = landmarks_pre_processing(\n",
    "                    landMarksList)\n",
    "                \n",
    "                \n",
    "                # save pre- processed landmarks to CSV\n",
    "                saving_landmarks_csv(num, status, landmarksPreProcessed)\n",
    "                \n",
    "\n",
    "                #  sign interpreter \n",
    "                handSignId = LandMarkClassifier(landmarksPreProcessed)\n",
    "               \n",
    "\n",
    "                # Output Display \n",
    "                outputDisplay = drawing_bounding_rectangle(uBrec,BGRImag,boundingRec)\n",
    "                outputDisplay = draw_landmarks(BGRImag,landMarksList)\n",
    "                outputDisplay = output_signs(BGRImag,boundingRec,multiHandedness,landMarksLabels[handSignId])\n",
    "        \n",
    "\n",
    "        \n",
    "        outputDisplay = draw_extraction_info(BGRImag,status,num)\n",
    "\n",
    "        # Display header\n",
    "        cv.imshow('Sign Language Recognition',BGRImag)\n",
    "\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88b06a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "     run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28450e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
